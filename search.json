[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/HW0/index.html",
    "href": "posts/HW0/index.html",
    "title": "HW0",
    "section": "",
    "text": "Introduction and Getting Started\nToday, we’re going to use python to construct an interesting data visualization of the Palmer Penguins dataset. You can read the data into python by running the following code:\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\nAdditionally, we’re going to want to import both seaborn and matplotlib to create our plots. To do this, run the following code.\n\nimport seaborn as sns \nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n\nAnalyzing the Dataset\nNow let’s take a look at the dataset. To get an idea of what it looks like, let’s inspect the first five rows of our penguins DataFrame, using the .head() function as seen below.\n\npenguins.head(5)\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n\n\n\n\n\nAs we can see, the data holds recorded measurements of Culmen length and depth, flipper length, and body mass, with indentifiers such as the study name, sample number, species, region, island, stage, individual id, clutch completion, egg date, and sex. In all, there 17 columns for each entry.\n\n\nVisualizing the Correlations in the Dataset\nLet’s try and find a correlation between measurements. Take flipper length and body mass. An interesting hypothesis would be that as flipper length increases, so does body mass. Let’s visualize this using a scatterplot. We’ll use seaborn and matplotlib along with the “penguins” dataframe we made earlier. The code is as follows:\n\nsns.scatterplot(data=penguins, x=\"Flipper Length (mm)\", y=\"Body Mass (g)\")\nplt.title(\"Penguin Flipper Length Affect On Body Mass\")\nplt.show\n\n\n\n\n\n\n\n\nWe take data from our penguins DataFrame, specifically from the “Flipper Length (mm)” and “Body Mass (g)” columns. We use seaborn as a shortcut to using matplotlib functions, like scatterplot as above. Pass penguins, “Flipper Length (mm),” and “Body Mass (g)” as arguments to sns.scatterplot. Choose a preferred title, and plot using plt.show. As a further modification, we can add a line of best fit by using sns.regplot, which autofits a line of regression. It’s produced as follows:\n\nsns.regplot(data=penguins, x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", scatter_kws={\"color\":\"blue\"}, line_kws={\"color\":\"red\"})\nplt.title(\"Penguin Flipper Length Affect On Body Mass\")\nplt.show\n\n\n\n\n\n\n\n\nHere, scatter_kws and line_kws are both dictionaries that allow us to change the colors of the datapoints and line of best fit. Body mass and flipper length seem to be directly proportional. This makes sense, since the larger the flipper, the heavier it is, thus increasing body mass."
  },
  {
    "objectID": "posts/HW5/index.html",
    "href": "posts/HW5/index.html",
    "title": "Exploring Image Classification and Transfer Learning in Keras",
    "section": "",
    "text": "Introduction\nToday we’re going to look at image classification and transfer learning using the very useful keras library in python, with backend tensorflow. To start, you’ll need to import the following:\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport keras\nfrom keras import utils\nimport keras.layers\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nWorking with a Dataset\nWe’re going to use the “cats vs dogs” dataset from Kaggle, loading it in through tensorflow datasets (that’s why we imported it above). Let’s look at the datasets details.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nDownloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\nDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\n\n\nRun the code above to download the dataset. As we can see, the data set has around 14,000 images in it, which we split up into images for training, images for validation, and images for testing (a 40/40/10 split). These three datasets are the backbone of today’s project – we’re going to keep coming back to them over and over. As a refresher, lets go over what training, validation, and testing are. As you can probably guess, the training dataset is used to train our model – the idea is that the machine can recognize patterns evident in the training data, and locate them in other pictures to identify what they are. Validation is a sort of test-before-the-actual-test, where we make sure our model is recognizing the appropriate details, and not overfitting to only classify the training data. Finally, the test set is as it sounds – the final test of our model’s ability to classify images.\nIn the following, we do a little bit more manipulation of the datasets. We use the Resizing() method to make sure all images in the cats vs dogs dataset are the same pixel size, here being 150x150. We then apply this change to the training, validation, and test sets separately. Next, we dig place our data in cache for ease of access when actually running code. This way we don’t take forever to check our model’s accuracy.\n\nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\n\n\nfrom tensorflow import data as tf_data\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nNext, I made a little visual of the dataset. Using matplotlib, and iterating through the first batch of data in the train dataset (that’s what the take() function is for – take(n) returns us the nth batch of data), we can make two rows of plots, the first with three different photos of cats, the second with three different photos of dogs.\n\ndef visualize(dataset):\n  plt.figure(figsize=(10, 5))\n  cats = []\n  dogs = []\n  for images, labels in dataset.take(1): # iterate through first batch of data in dataset\n    for i in range(len(labels)):\n      if labels[i] == 0:\n        cats.append(images[i].numpy().astype(\"uint8\"))\n      else:\n        dogs.append(images[i].numpy().astype(\"uint8\"))\n    for i in range(3):\n      ax = plt.subplot(2, 3, i + 1) # first row of plots, for cats\n      plt.imshow(cats[i])\n      plt.title('Cat')\n      plt.axis('off')\n\n      ax = plt.subplot(2, 3, i + 4) # second row of plots, for dogs\n      plt.imshow(dogs[i])\n      plt.title('Dog')\n      plt.axis('off')\n\nvisualize(train_ds)\n\n\n\n\n\n\n\n\nThis is the final part of our introduction. A baseline machine learning model, in theory, just guesses the majority data class each time. I created an iterator of the train data below, and looped through it to count how many dogs images and how many cat images are in the set. As you can see, dogs slighlty outnumber cats. Thus, we’d expect to see a little over 50% success rate from a baseline model just guessing dog for each image.\n\nlabels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\ndog_count = 0\ncat_count = 0\nfor label in labels_iterator:\n  if label == 0:\n    cat_count+= 1\n  else:\n    dog_count+= 1\n\nprint(f'num cats: {cat_count} num dogs: {dog_count}')\n\nnum cats: 4637 num dogs: 4668\n\n\n\n\nOur First Model\nOur first model is going to be pretty simply. In all of these, we utilize keras.Sequential to create a pipeline through which data will flow. Here, we have three convolutional layers, 3 max pooling layers, two dropout layers, one layer to flatten data, and a final dense layer with two outputs – the probability spread of whether or not an image is a dog or cat (not quite, actually – the last layer just gives us raw values, not probabilities, as it turns out we don’t need those yet).\n\nfrom keras import layers\nmodel1 = keras.models.Sequential([\n    layers.Input((150, 150, 3)),\n    layers.Conv2D(150, (5, 5), activation='relu'),\n    layers.MaxPooling2D((3,3)),\n    layers.Dropout(0.2),\n    layers.Conv2D(150, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Dropout(0.2),\n    layers.Conv2D(256, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Flatten(),\n    layers.Dense(2)\n])\n\nThe following is the code we use to start the process of training our model. We compile the model using an optimizer called ‘adam’ to perform the technique known as gradient descent: the process in which the model “learns” what weights provide the best prediction. Equally as import is our loss function. Here we use Sparse Categorical Cross Entropy Loss (from the logits, the raw values we get back from the final dense layer in our model). The loss is what we try to minimize when creating a model. Finally, we have our metric to measure the model’s performance – its accuracy when classifying images.\n\nmodel1.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics='accuracy')\n\nhistory = model1.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 23s 151ms/step - loss: 7.8524 - accuracy: 0.5444 - val_loss: 0.6831 - val_accuracy: 0.5636\nEpoch 2/20\n146/146 [==============================] - 22s 149ms/step - loss: 0.6558 - accuracy: 0.5981 - val_loss: 0.6326 - val_accuracy: 0.6595\nEpoch 3/20\n146/146 [==============================] - 22s 151ms/step - loss: 0.6084 - accuracy: 0.6690 - val_loss: 0.5845 - val_accuracy: 0.6917\nEpoch 4/20\n146/146 [==============================] - 22s 150ms/step - loss: 0.5741 - accuracy: 0.6987 - val_loss: 0.5601 - val_accuracy: 0.7395\nEpoch 5/20\n146/146 [==============================] - 22s 152ms/step - loss: 0.5432 - accuracy: 0.7238 - val_loss: 0.5193 - val_accuracy: 0.7575\nEpoch 6/20\n146/146 [==============================] - 22s 150ms/step - loss: 0.5098 - accuracy: 0.7487 - val_loss: 0.5509 - val_accuracy: 0.7175\nEpoch 7/20\n146/146 [==============================] - 22s 149ms/step - loss: 0.4970 - accuracy: 0.7582 - val_loss: 0.4856 - val_accuracy: 0.7691\nEpoch 8/20\n146/146 [==============================] - 22s 148ms/step - loss: 0.4698 - accuracy: 0.7768 - val_loss: 0.5095 - val_accuracy: 0.7588\nEpoch 9/20\n146/146 [==============================] - 22s 149ms/step - loss: 0.4495 - accuracy: 0.7851 - val_loss: 0.4877 - val_accuracy: 0.7683\nEpoch 10/20\n146/146 [==============================] - 22s 152ms/step - loss: 0.4421 - accuracy: 0.7927 - val_loss: 0.6544 - val_accuracy: 0.6681\nEpoch 11/20\n146/146 [==============================] - 22s 148ms/step - loss: 0.4322 - accuracy: 0.7962 - val_loss: 0.4758 - val_accuracy: 0.7868\nEpoch 12/20\n146/146 [==============================] - 22s 150ms/step - loss: 0.4095 - accuracy: 0.8076 - val_loss: 0.4950 - val_accuracy: 0.7812\nEpoch 13/20\n146/146 [==============================] - 22s 150ms/step - loss: 0.3911 - accuracy: 0.8198 - val_loss: 0.4860 - val_accuracy: 0.7769\nEpoch 14/20\n146/146 [==============================] - 22s 149ms/step - loss: 0.3855 - accuracy: 0.8214 - val_loss: 0.4935 - val_accuracy: 0.7880\nEpoch 15/20\n146/146 [==============================] - 22s 149ms/step - loss: 0.3726 - accuracy: 0.8284 - val_loss: 0.5129 - val_accuracy: 0.7807\nEpoch 16/20\n146/146 [==============================] - 22s 148ms/step - loss: 0.3455 - accuracy: 0.8478 - val_loss: 0.4949 - val_accuracy: 0.7876\nEpoch 17/20\n146/146 [==============================] - 22s 151ms/step - loss: 0.3528 - accuracy: 0.8418 - val_loss: 0.5555 - val_accuracy: 0.7502\nEpoch 18/20\n146/146 [==============================] - 22s 150ms/step - loss: 0.3214 - accuracy: 0.8638 - val_loss: 0.5148 - val_accuracy: 0.7928\nEpoch 19/20\n146/146 [==============================] - 22s 151ms/step - loss: 0.3222 - accuracy: 0.8619 - val_loss: 0.5286 - val_accuracy: 0.7782\nEpoch 20/20\n146/146 [==============================] - 22s 151ms/step - loss: 0.3026 - accuracy: 0.8686 - val_loss: 0.5782 - val_accuracy: 0.7807\n\n\nThe following plot showcases the tradeoffs between validation and train accuracy. Validation accuracy flucutates, for the most part, in the 75% to 77% range, with a few outliers. Near the end of the training process, you can observe a widening gap between training and validation accuracy – this is caused by overfitting, the tendency of our model to get too used to the train data (it gets a sort of tunnel vision, and loses valuable information when keying in on patterns that are not global to the dataset). Even with this issue, however, our model still blows the baseline out of the water.\n\nplt.plot(history.history[\"accuracy\"], label = \"training\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Visualizing Our First Attempt\")\n\nText(0.5, 1.0, 'Visualizing Our First Attempt')\n\n\n\n\n\n\n\n\n\n\n\nUtilizing Data Augmentation\nOur last model was fine, but I think we can still do better, or at least start the process of getting better with this next approach. Here, we’re going to employ data augmentation, in the form of random flips and rotations, making our model more robust. Below, I wrote some code to create new layers that can be slotted into our keras.Sequential model pipeline. We have flip, which is a layer involving a random flip, and rotation, a layer involving a random rotation. I visualized it in a plot following the code – on the top left we have a picture of a dog, to its right a random flip, and on the bottom row, two random rotations of the image.\n\nflip = tf.keras.layers.RandomFlip()\nrotation = tf.keras.layers.RandomRotation(0.5)\n\nfor image, _ in train_ds.take(1):\n  plt.figure(figsize=(10, 5))\n  first_image = image[0]\n  for i in range(2):\n    ax = plt.subplot(2, 3, i + 1) # First row, with original image and flipped image\n    augmented_image = flip(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] / 255)\n    plt.axis('off')\n    ax = plt.subplot(2, 3, i + 4) # Second row, with two randomly rotated versions of the original image\n    augmented_image = rotation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] / 255)\n    plt.axis('off')\n\n\n\n\n\n\n\n\nNext, we put these layers into our model pipeline. Keep them at the top, so the changes to the images are taken into account by every layer. Model 2 is the exact same as Model 1, just with the added flip and rotation layers.\n\nflip = tf.keras.layers.RandomFlip()\nrotation = tf.keras.layers.RandomRotation(0.2)\n\nmodel2 = keras.models.Sequential([\n    layers.Input((150, 150, 3)),\n    flip,\n    rotation,\n    layers.Conv2D(150, (5,5), activation='relu'),\n    layers.MaxPooling2D((3,3)),\n    layers.Dropout(0.2),\n    layers.Conv2D(150, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Dropout(0.2),\n    layers.Conv2D(256, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Flatten(),\n    layers.Dense(2)\n])\n\nWe use the same parameters in training Model 2.\n\nmodel2.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics='accuracy')\n\nhistory = model2.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 25s 154ms/step - loss: 5.9194 - accuracy: 0.5279 - val_loss: 0.6839 - val_accuracy: 0.5525\nEpoch 2/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6839 - accuracy: 0.5609 - val_loss: 0.6836 - val_accuracy: 0.5598\nEpoch 3/20\n146/146 [==============================] - 23s 154ms/step - loss: 0.6760 - accuracy: 0.5788 - val_loss: 0.6816 - val_accuracy: 0.5856\nEpoch 4/20\n146/146 [==============================] - 22s 152ms/step - loss: 0.6708 - accuracy: 0.5876 - val_loss: 0.6782 - val_accuracy: 0.5864\nEpoch 5/20\n146/146 [==============================] - 22s 152ms/step - loss: 0.6727 - accuracy: 0.5845 - val_loss: 0.6612 - val_accuracy: 0.6152\nEpoch 6/20\n146/146 [==============================] - 22s 152ms/step - loss: 0.6618 - accuracy: 0.6063 - val_loss: 0.6555 - val_accuracy: 0.6191\nEpoch 7/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6572 - accuracy: 0.6191 - val_loss: 0.6541 - val_accuracy: 0.6135\nEpoch 8/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6736 - accuracy: 0.5682 - val_loss: 0.6914 - val_accuracy: 0.4987\nEpoch 9/20\n146/146 [==============================] - 22s 151ms/step - loss: 0.6867 - accuracy: 0.5336 - val_loss: 0.6898 - val_accuracy: 0.5245\nEpoch 10/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6843 - accuracy: 0.5516 - val_loss: 0.6900 - val_accuracy: 0.5133\nEpoch 11/20\n146/146 [==============================] - 24s 163ms/step - loss: 0.6751 - accuracy: 0.5796 - val_loss: 0.6794 - val_accuracy: 0.5576\nEpoch 12/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6630 - accuracy: 0.6026 - val_loss: 0.6661 - val_accuracy: 0.5847\nEpoch 13/20\n146/146 [==============================] - 22s 154ms/step - loss: 0.6562 - accuracy: 0.6190 - val_loss: 0.6547 - val_accuracy: 0.6019\nEpoch 14/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6504 - accuracy: 0.6282 - val_loss: 0.6582 - val_accuracy: 0.6255\nEpoch 15/20\n146/146 [==============================] - 23s 154ms/step - loss: 0.6521 - accuracy: 0.6269 - val_loss: 0.6476 - val_accuracy: 0.6397\nEpoch 16/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6399 - accuracy: 0.6382 - val_loss: 0.6473 - val_accuracy: 0.6273\nEpoch 17/20\n146/146 [==============================] - 23s 160ms/step - loss: 0.6419 - accuracy: 0.6382 - val_loss: 0.6444 - val_accuracy: 0.6359\nEpoch 18/20\n146/146 [==============================] - 22s 151ms/step - loss: 0.6447 - accuracy: 0.6356 - val_loss: 0.6365 - val_accuracy: 0.6337\nEpoch 19/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6478 - accuracy: 0.6347 - val_loss: 0.6469 - val_accuracy: 0.6294\nEpoch 20/20\n146/146 [==============================] - 22s 153ms/step - loss: 0.6501 - accuracy: 0.6256 - val_loss: 0.6266 - val_accuracy: 0.6574\n\n\nSo Model 2 doesn’t perform as well as Model 1. Why? Well it seems to me as if the model requires a larger training period. There is really no overfitting, but the model doesn’t quite have enough time to adjust to the changes pushed by the data augmentation. If it had more time in the oven, I have no doubt it would continue to perform well. Still, it may not have done better than Model 1. Overall, the validation accuracy of Model 2 was kind of all over the place – while it made it past 60% in the end, there was a portion of time where it dipped below 50% before regaining form.\n\nplt.plot(history.history[\"accuracy\"], label = \"training\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Utilizing Data Augmentation\")\n\nText(0.5, 1.0, 'Utilizing Data Augmentation')\n\n\n\n\n\n\n\n\n\n\n\nWith Preprocessing\nSometimes it helps to modify the data on the pixel level. That’s what we’re doing in this next model. The code before our Sequential pipeline is used to squash the pixel values of the image, reducing it from the usual 0 to 255 you see most of time. This will helpe standardize the images, helping the classification process.\n\ni = keras.Input(shape=(150, 150, 3))\n# The pixel values have the range of (0, 255), but many models will work better if rescaled to (-1, 1.)\n# outputs: `(inputs * scale) + offset`\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs = i, outputs = x)\n\nmodel3 = keras.models.Sequential([\n    preprocessor,\n    flip,\n    rotation,\n    layers.Conv2D(150, (5,5), activation='relu'),\n    layers.MaxPooling2D((3,3)),\n    layers.Dropout(0.2),\n    layers.Conv2D(150, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Dropout(0.2),\n    layers.Conv2D(256, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.Flatten(),\n    layers.Dense(2)\n])\n\n\nmodel3.compile(optimizer='adam',\n               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n               metrics='accuracy')\n\nhistory = model3.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 28s 178ms/step - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6737 - val_accuracy: 0.5834\nEpoch 2/20\n146/146 [==============================] - 25s 173ms/step - loss: 0.6676 - accuracy: 0.5666 - val_loss: 0.6677 - val_accuracy: 0.6002\nEpoch 3/20\n146/146 [==============================] - 25s 173ms/step - loss: 0.6562 - accuracy: 0.5940 - val_loss: 0.6656 - val_accuracy: 0.5722\nEpoch 4/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.6535 - accuracy: 0.5980 - val_loss: 0.5995 - val_accuracy: 0.6655\nEpoch 5/20\n146/146 [==============================] - 26s 181ms/step - loss: 0.6145 - accuracy: 0.6603 - val_loss: 0.5874 - val_accuracy: 0.6956\nEpoch 6/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.5908 - accuracy: 0.6830 - val_loss: 0.5744 - val_accuracy: 0.6995\nEpoch 7/20\n146/146 [==============================] - 25s 170ms/step - loss: 0.5797 - accuracy: 0.6945 - val_loss: 0.5661 - val_accuracy: 0.7051\nEpoch 8/20\n146/146 [==============================] - 25s 170ms/step - loss: 0.5720 - accuracy: 0.6984 - val_loss: 0.5656 - val_accuracy: 0.7046\nEpoch 9/20\n146/146 [==============================] - 25s 174ms/step - loss: 0.5590 - accuracy: 0.7069 - val_loss: 0.5301 - val_accuracy: 0.7356\nEpoch 10/20\n146/146 [==============================] - 25s 172ms/step - loss: 0.5494 - accuracy: 0.7190 - val_loss: 0.5265 - val_accuracy: 0.7326\nEpoch 11/20\n146/146 [==============================] - 25s 173ms/step - loss: 0.5462 - accuracy: 0.7197 - val_loss: 0.5302 - val_accuracy: 0.7326\nEpoch 12/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.5370 - accuracy: 0.7287 - val_loss: 0.5239 - val_accuracy: 0.7386\nEpoch 13/20\n146/146 [==============================] - 25s 169ms/step - loss: 0.5298 - accuracy: 0.7328 - val_loss: 0.5121 - val_accuracy: 0.7438\nEpoch 14/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.5257 - accuracy: 0.7367 - val_loss: 0.5103 - val_accuracy: 0.7425\nEpoch 15/20\n146/146 [==============================] - 25s 170ms/step - loss: 0.5183 - accuracy: 0.7395 - val_loss: 0.5035 - val_accuracy: 0.7528\nEpoch 16/20\n146/146 [==============================] - 25s 169ms/step - loss: 0.5107 - accuracy: 0.7505 - val_loss: 0.5091 - val_accuracy: 0.7519\nEpoch 17/20\n146/146 [==============================] - 26s 176ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.5156 - val_accuracy: 0.7451\nEpoch 18/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.4978 - accuracy: 0.7556 - val_loss: 0.4710 - val_accuracy: 0.7790\nEpoch 19/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.4931 - accuracy: 0.7554 - val_loss: 0.4682 - val_accuracy: 0.7825\nEpoch 20/20\n146/146 [==============================] - 25s 171ms/step - loss: 0.4924 - accuracy: 0.7556 - val_loss: 0.5020 - val_accuracy: 0.7648\n\n\nModel 3 is the mostly the same as the previous two, with the only new additions being the preprocessing layer noted above and an extra convolution before the flatenning. It shows remarkable improvement over Model 2 in terms of accuracy, and Model 1 because of its lack of overfitting. Validation accuracy is just about 80% at its peak, but with no signs of overfitting and a clear upward (though stagnating) trend, with a larger training period, Model 3 could have soared to levels over 85%.\n\nplt.plot(history.history[\"accuracy\"], label = \"training\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"Utilizing Preprocessing\")\n\nText(0.5, 1.0, 'Utilizing Preprocessing')\n\n\n\n\n\n\n\n\n\n\n\nExploring Transfer Learning\nSometimes, instead of taking the time to train our own model, its easier (and more rewarding) to utilize a pretrained model to help us along the way. At its core, that’s what transfer learning allows us to do. For our penultimate model, Model 4, we utilize the extremely powerful MovileNetV3 CNN architecture as a layer in our pipeline. We follow it up with a global max pool and one dropout layer before passing to a dense layer with two outputs to classify images.\n\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training = False)\nbase_model_layer = keras.Model(inputs = i, outputs = x)\n\nWARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n12683000/12683000 [==============================] - 0s 0us/step\n\n\n\nmodel4 = keras.models.Sequential([\n    flip,\n    rotation,\n    base_model_layer,\n    layers.GlobalMaxPool2D(),\n    layers.Dropout(0.2),\n    layers.Dense(2)\n])\n\n\nmodel4.compile(optimizer='adam',\n               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n               metrics='accuracy')\n\nhistory = model4.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 15s 63ms/step - loss: 1.6207 - accuracy: 0.8264 - val_loss: 0.2941 - val_accuracy: 0.9570\nEpoch 2/20\n146/146 [==============================] - 6s 42ms/step - loss: 0.9651 - accuracy: 0.8828 - val_loss: 0.2595 - val_accuracy: 0.9639\nEpoch 3/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.7959 - accuracy: 0.8905 - val_loss: 0.2713 - val_accuracy: 0.9592\nEpoch 4/20\n146/146 [==============================] - 7s 48ms/step - loss: 0.5745 - accuracy: 0.9064 - val_loss: 0.1897 - val_accuracy: 0.9652\nEpoch 5/20\n146/146 [==============================] - 7s 48ms/step - loss: 0.5264 - accuracy: 0.9040 - val_loss: 0.1131 - val_accuracy: 0.9708\nEpoch 6/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4577 - accuracy: 0.9077 - val_loss: 0.2525 - val_accuracy: 0.9497\nEpoch 7/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.4424 - accuracy: 0.9023 - val_loss: 0.1890 - val_accuracy: 0.9604\nEpoch 8/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.4264 - accuracy: 0.9011 - val_loss: 0.1752 - val_accuracy: 0.9587\nEpoch 9/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.3756 - accuracy: 0.9080 - val_loss: 0.2174 - val_accuracy: 0.9514\nEpoch 10/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.3204 - accuracy: 0.9110 - val_loss: 0.1821 - val_accuracy: 0.9514\nEpoch 11/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3562 - accuracy: 0.9050 - val_loss: 0.1203 - val_accuracy: 0.9652\nEpoch 12/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.3646 - accuracy: 0.8996 - val_loss: 0.1940 - val_accuracy: 0.9475\nEpoch 13/20\n146/146 [==============================] - 7s 47ms/step - loss: 0.3423 - accuracy: 0.9037 - val_loss: 0.1437 - val_accuracy: 0.9549\nEpoch 14/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3412 - accuracy: 0.9070 - val_loss: 0.2421 - val_accuracy: 0.9355\nEpoch 15/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.3567 - accuracy: 0.9063 - val_loss: 0.1514 - val_accuracy: 0.9579\nEpoch 16/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.3247 - accuracy: 0.9060 - val_loss: 0.0995 - val_accuracy: 0.9665\nEpoch 17/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3501 - accuracy: 0.9054 - val_loss: 0.1437 - val_accuracy: 0.9561\nEpoch 18/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3778 - accuracy: 0.9042 - val_loss: 0.1680 - val_accuracy: 0.9514\nEpoch 19/20\n146/146 [==============================] - 7s 47ms/step - loss: 0.3688 - accuracy: 0.9008 - val_loss: 0.1687 - val_accuracy: 0.9553\nEpoch 20/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3485 - accuracy: 0.9012 - val_loss: 0.2262 - val_accuracy: 0.9321\n\n\nModel 4 is the pinnacle of our work here today. It has none of the drawbacks of Models 1, 2, and 3, and blows them each out of the water in terms of accuracy. The validation accuracy of Model 4 hovers between 94% and 96%, never once dropping below 93%.\n\nplt.plot(history.history[\"accuracy\"], label = \"training\")\nplt.plot(history.history[\"val_accuracy\"], label = \"validation\")\nplt.gca().set(xlabel = \"epoch\", ylabel = \"accuracy\")\nplt.legend()\nplt.title(\"With Transfer Learning\")\n\nText(0.5, 1.0, 'With Transfer Learning')\n\n\n\n\n\n\n\n\n\n\n\nThe Final Test\nLet’s see how good Model 4 really is by testing it on the unused test dataset we formed all those sections ago. We can measure test loss and test accuracy using the evaluate() function. Model 4 achieves a 92.3044% accuracy on the test set, a little bit lower than its validation accuracy was while a bit higher than train accuracy.\n\ntest_loss, test_accuracy = model4.evaluate(test_ds) # evaluate the model on test_ds\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)\n\n37/37 [==============================] - 3s 75ms/step - loss: 0.3023 - accuracy: 0.9230\nTest Loss: 0.3023127019405365\nTest Accuracy: 0.9230438470840454"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Exploring Image Classification and Transfer Learning in Keras\n\n\n\n\n\n\nMachine Learning\n\n\nHW\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nNarayanan Kannan\n\n\n\n\n\n\n\n\n\n\n\n\nHW0\n\n\n\n\n\n\nweek 0\n\n\nHW\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nNarayanan Kannan\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 14, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 11, 2024\n\n\nNarayanan Kannan\n\n\n\n\n\n\nNo matching items"
  }
]